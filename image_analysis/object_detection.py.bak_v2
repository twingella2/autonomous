import subprocess
import numpy as np
import tflite_runtime.interpreter as tflite
from PIL import Image

# Initialize the TFLite interpreter
def main():
    interpreter = tflite.Interpreter(model_path='/home/twingella/autonomous/models/model.tflite')
    interpreter.allocate_tensors()

    # Get input and output details
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

# Get the expected shape of the input tensor
expected_shape = input_details[0]['shape']
print("Expected input shape:", expected_shape)

# Capture an image using libcamera
subprocess.run(["libcamera-still", "-o", "frame.jpg"])

# Load and preprocess the image
image = Image.open('frame.jpg').convert('RGB')
image_resized = image.resize((expected_shape[1], expected_shape[2]))
image_np = np.array(image_resized)

# Check if the captured image shape matches the expected input shape
print("Actual image shape:", image_np.shape)

if image_np.shape[:2] == tuple(expected_shape[1:3]):
    input_array = np.expand_dims(image_np, axis=0)
else:
    print(f"Cannot reshape image of shape {image_np.shape} to expected shape {expected_shape}")
    exit(1)

# Perform inference
interpreter.set_tensor(input_details[0]['index'], input_array.astype(np.uint8))
interpreter.invoke()

# Get the output tensor
output_data = interpreter.get_tensor(output_details[0]['index'])

# Check the size of the output_data
output_size = len(output_data[0])

# Analyze the output (Example: get the index of the most confident object detected)
max_index = np.argmax(output_data[0])

if max_index < output_size:
    print(f"Detected object: {output_data[0][max_index]}")
else:
    print(f"Index out of bounds. Max index: {max_index}, Output size: {output_size}")


if __name__ == "__main__":
    main()